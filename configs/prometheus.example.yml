global:
  scrape_interval:     5s # By default, scrape targets every 15 seconds.
  evaluation_interval: 5s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  # external_labels:
  #     cluster: demo
  #     __replica__: replica-{{.Task.Slot}}

# Write samples to Grafana Mimir
# remote_write:
#   - url: http://mimir:3200/api/v1/push
#     headers:
#       "X-Scope-OrgID": demo

alerting:
  alertmanagers:
    # Remote alertmanager
    # - url: http://alertmanager:9093

    # !!! It is recommended to leave this config block below untouched !!!
    # Local cluster alertmanager with DNS discovery
    - dns_sd_configs:
        - names:
          - 'tasks.alertmanager'
          type: 'A'
          port: 9093

  # All alerts sent to the Alertmanager will then also have different replica labels.
  # Since the Alertmanager dedupes alerts based on identical label sets, 
  # this deduplication will now break and you will get as many notifications as you have Prometheus server replicas!
  # To avoid this, make sure that you drop the replica label on the alerting path using alert relabeling:
  alert_relabel_configs:
    # Drop the "replica" label.
    - action: labeldrop
      regex: __replica__

# Load and evaluate rules in this file every 'evaluation_interval' seconds.
rule_files:
  - "rules/node.yml"
  - "rules/service.yml"
  - "rules/task.yml"

# Scrape config files specifies a list of globs. Scrape configs are read from
# all matching files and appended to the list of scrape configs.
scrape_config_files:
  - "scrape_configs/docker.yml"
  - "scrape_configs/dockerswarm.yml"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # Here it's Prometheus itself.
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
